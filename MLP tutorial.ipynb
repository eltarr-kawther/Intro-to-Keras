{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c01de74",
   "metadata": {},
   "source": [
    "# Intro to Keras with breast cancer data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eaa152",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114a19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d13edce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9   ...        21     22     23      24      25      26      27  \\\n",
       "0  0.14710  ...  0.006193  25.38  17.33  184.60  2019.0  0.1622  0.6656   \n",
       "1  0.07017  ...  0.003532  24.99  23.41  158.80  1956.0  0.1238  0.1866   \n",
       "2  0.12790  ...  0.004571  23.57  25.53  152.50  1709.0  0.1444  0.4245   \n",
       "3  0.10520  ...  0.009208  14.91  26.50   98.87   567.7  0.2098  0.8663   \n",
       "4  0.10430  ...  0.005115  22.54  16.67  152.20  1575.0  0.1374  0.2050   \n",
       "\n",
       "       28      29      30  \n",
       "0  0.7119  0.2654  0.4601  \n",
       "1  0.2416  0.1860  0.2750  \n",
       "2  0.4504  0.2430  0.3613  \n",
       "3  0.6869  0.2575  0.6638  \n",
       "4  0.4000  0.1625  0.2364  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"Data/WDBC.csv\", header=None)\n",
    "del df[31]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b7ebf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc820cb",
   "metadata": {},
   "source": [
    "## Set features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "685b0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 2:].values\n",
    "y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6990e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 29)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8daa6",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae965a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e4d98",
   "metadata": {},
   "source": [
    "## Splitting the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1825a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394fecac",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5bd99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0795d03e",
   "metadata": {},
   "source": [
    "## Define ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60223ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units=16, kernel_initializer=\"uniform\", activation='relu', input_dim=29))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe2defe",
   "metadata": {},
   "source": [
    "## Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df07017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477afba5",
   "metadata": {},
   "source": [
    "## Fitting the ANN to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b86300eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.6879\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.8000\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.8769\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6591 - accuracy: 0.9055\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.9253\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.9297\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.9275\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.9363\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5554 - accuracy: 0.9363\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.9363\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.9407\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.9429\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.9451\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.9495\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3746 - accuracy: 0.9516\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.9516\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.9538\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.9560\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.9582\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.9582\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.9604\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9648\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.9648\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2089 - accuracy: 0.9648\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.9692\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9714\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.9736\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.9714\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1632 - accuracy: 0.98 - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9736\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.9736\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9758\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.9758\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9736\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9758\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.98 - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9758\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1317 - accuracy: 0.9758\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9758\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1279 - accuracy: 0.9758\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.9758\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9758\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.9736\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.99 - 0s 2ms/step - loss: 0.1166 - accuracy: 0.9758\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9780\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9758\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9736\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9780\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9780\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.9780\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9802\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9802\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9802\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9802\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9802\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.9802\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9802\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9802\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9824\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.9802\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0890 - accuracy: 0.9802\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9824\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9802\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.9802\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9824\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.9824\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9824\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9846\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0802 - accuracy: 0.9824\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9802\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.9824\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9802\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9824\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.9846\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.99 - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9824\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9824\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.9824\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9846\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9846\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9846\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.9868\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9868\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9846\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9846\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9890\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9868\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9890\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9890\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9846\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9868\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9846\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9890\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9868\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9868\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9890\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9890\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9868\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9890\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9890\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9890\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9868\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9890\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9868\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9890\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9890\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9890\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9890\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9890\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9890\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9890\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9868\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9868\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9890\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9868\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9890\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9890\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9890\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9890\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9890\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9890\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9890\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9890\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9890\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9890\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9868\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9890\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9890\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9890\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9890\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9890\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9890\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9890\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9890\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9890\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9890\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9890\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9890\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9890\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9890\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9868\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9890\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9890\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9890\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9890\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9890\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9890\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9890\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9890\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9890\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9890\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1feaca42ac0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size=100, epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97264ff6",
   "metadata": {},
   "source": [
    "## Predicting the test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e789dd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37d653",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b92e71e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64,  3],\n",
       "       [ 3, 44]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "293029f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe41bf0",
   "metadata": {},
   "source": [
    "## Accuracy of ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6887ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy is 189.4736842105263%\n"
     ]
    }
   ],
   "source": [
    "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/57)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4772ca",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56a72d2",
   "metadata": {},
   "source": [
    "- **Breast Cancer Wisconsin (Diagnostic) Data Set**: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "- **Intro to Keras with breast cancer data[ANN]** : https://www.kaggle.com/thebrownviking20/intro-to-keras-with-breast-cancer-data-ann/notebook\n",
    "- **[ANN] Making Model for Binary Classification** : https://www.kaggle.com/mirichoi0218/ann-making-model-for-binary-classification\n",
    "- **Why do we use ReLU in neural networks and how do we use it?** : https://stats.stackexchange.com/questions/226923/why-do-we-use-relu-in-neural-networks-and-how-do-we-use-it\n",
    "- **Activation Functions: Sigmoid, Tanh, ReLU, Leaky ReLU, Softmax** : https://medium.com/@cmukesh8688/activation-functions-sigmoid-tanh-relu-leaky-relu-softmax-50d3778dcea5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
