{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c01de74",
   "metadata": {},
   "source": [
    "# Intro to Keras with breast cancer data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eaa152",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114a19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d13edce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"Data/WDBC.csv\", header=None, names=[\"id\", \"diagnosis\", \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\", \"concave points_mean\", \"symmetry_mean\", \"fractal_dimension_mean\", \"radius_se\", \"texture_se\", \"perimeter_se\", \"area_se\", \"smoothness_se\", \"compactness_se\", \"concavity_se\", \"concave points_se\", \"symmetry_se\", \"fractal_dimension_se\", \"radius_worst\", \"texture_worst\", \"perimeter_worst\", \"area_worst\", \"smoothness_worst\", \"compactness_worst\", \"concavity_worst\", \"concave points_worst\", \"symmetry_worst\", \"fractal_dimension_worst\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3ea39",
   "metadata": {},
   "source": [
    "## Attribute Information :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd582e5",
   "metadata": {},
   "source": [
    "- 1) ID number \n",
    "- 2) Diagnosis (M = malignant, B = benign)\n",
    "- 3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus :\n",
    "\n",
    "- **a)** radius (mean of distances from center to points on the perimeter) \n",
    "- **b)** texture (standard deviation of gray-scale values) \n",
    "- **c)** perimeter \n",
    "- **d)** area \n",
    "- **e)** smoothness (local variation in radius lengths)\n",
    "- **f)** compactness (perimeterÂ² / area - 1.0) \n",
    "- **g)** concavity (severity of concave portions of the contour) \n",
    "- **h)** concave points (number of concave portions of the contour) \n",
    "- **i)** symmetry \n",
    "- **j)** fractal dimension (\"coastline approximation\" - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b7ebf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc820cb",
   "metadata": {},
   "source": [
    "## Set features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "685b0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 2:].values\n",
    "y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6990e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8daa6",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae965a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e4d98",
   "metadata": {},
   "source": [
    "## Splitting the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1825a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394fecac",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5bd99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0795d03e",
   "metadata": {},
   "source": [
    "## Define ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58cd792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d60223ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units=16, kernel_initializer=\"uniform\", activation='relu', input_dim=30))\n",
    "\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba0dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units=16, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b756b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67f5e97",
   "metadata": {},
   "source": [
    "Output_dim is 1 as we want only 1 output from the final layer. Sigmoid function is used when dealing with classfication problems with 2 types of results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe2defe",
   "metadata": {},
   "source": [
    "## Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df07017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7315a785",
   "metadata": {},
   "source": [
    "Optimizer is chosen as adam for gradient descent. Binary_crossentropy is the loss function used. \n",
    "\n",
    "Cross-entropy loss, or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label. So predicting a probability of 0.012 when the actual observation label is 1 would be bad and result in a high loss value. A perfect model would have a log loss of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477afba5",
   "metadata": {},
   "source": [
    "## Fitting the ANN to the Training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb21055",
   "metadata": {},
   "source": [
    "Batch size defines the number of samples that will be propagated through the network.\n",
    "\n",
    "An Epoch is a complete pass through all the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b86300eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 0.6926 - accuracy: 0.6374\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.7055\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.6877 - accuracy: 0.7802\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.8418\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.8989\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.9187\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.9319\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.9385\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.9473\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.9407\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.9473\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.9495\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.9538\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.4324 - accuracy: 0.9582\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.3936 - accuracy: 0.9582\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.9604\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.9604\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.9626\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.9692\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.2315 - accuracy: 0.9648\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2113 - accuracy: 0.9670\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9692\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9736\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9736\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.1507 - accuracy: 0.9736\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9736\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9736\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.9736\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.9780\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9802\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9780\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9802\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9802\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.9780\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.9802\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9824\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0863 - accuracy: 0.9824\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9802\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 0.9824\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9824\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0797 - accuracy: 0.9802\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9824\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9868\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9846\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0719 - accuracy: 0.9890\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9868\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9890\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9846\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9868\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9824\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9868\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9846\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0611 - accuracy: 0.9890\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9868\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9890\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0611 - accuracy: 0.9890\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9868\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9868\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0585 - accuracy: 0.9890\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9868\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.97 - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9868\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9890\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9890\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9890\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9890\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9890\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9868\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9890\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9912\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9890\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9890\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9890\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0536 - accuracy: 0.9890\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9890\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9890\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0509 - accuracy: 0.9890\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9890\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9890\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0494 - accuracy: 0.9890\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9890\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9890\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9890\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0499 - accuracy: 0.9890\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9890\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9890\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9890\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9890\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9912\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9890\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9912\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0483 - accuracy: 0.9912\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9890\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9912\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9912\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9890\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0460 - accuracy: 0.9912\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0434 - accuracy: 0.9912\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9912\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9890\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9912\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0428 - accuracy: 0.9912\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9890\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9890\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9912\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9912\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9912\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9890\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0404 - accuracy: 0.9890\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9868\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9912\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9912\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9890\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0429 - accuracy: 0.9912\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9912\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9890\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9912\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9912\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9912\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9912\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9912\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9890\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9912\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9912\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0427 - accuracy: 0.9912\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9912\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9912\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9912\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0428 - accuracy: 0.9912\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0412 - accuracy: 0.9912\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9912\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9912\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9912\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9912\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9912\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9912\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9912\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9912\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0369 - accuracy: 0.9912\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9912\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9890\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9912\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9912\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.0353 - accuracy: 0.9912\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9912\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9912\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9912\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9912\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9890\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9912\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d3760b970>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size=100, epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97264ff6",
   "metadata": {},
   "source": [
    "## Predicting the test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e789dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b89bb8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37d653",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b92e71e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[65,  2],\n",
       "       [ 3, 44]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "293029f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQ8ElEQVR4nO3de7CcdX3H8ff3JIck3BNzhSh4SUFwDLYIKOpQ09J4GYMzpqLVSZ2Mp/XS4qVIykgRrVOmWopTGfEQkLTaaApFUkbQeJDiNSEIKBAwTCohEhIBhSRoyDn77R9Z9UiSs3vI+Z1nz5P3K/PM7j67++yXmcwnX77Pb5+NzESSVE5X1QVIUt0ZtJJUmEErSYUZtJJUmEErSYWNL/0Bux7d4LIG7WHSUa+uugR1oP6nfxb7e4zhZE731Bfs9+e1o3jQStKoagxUXcEeDFpJ9ZKNqivYg0ErqV4aBq0kFZV2tJJU2EB/1RXswaCVVC+eDJOkwhwdSFJhngyTpLI8GSZJpdnRSlJhA7uqrmAPBq2kenF0IEmFdeDowMskSqqXbLS/tRARR0bENRFxX0Ssi4hXRMSUiFgVEeubt5NbHceglVQvjUb7W2ufAW7KzOOBucA6YAnQl5lzgL7m4yE5OpBUK9kYmZNhEXE48BrgLwEy82ng6YhYAJzRfNky4BbgvKGOZUcrqV5GrqN9AfBz4AsRcUdELI2IQ4AZmbkZoHk7vdWBDFpJ9TKMGW1E9ETE2kFbz6AjjQf+EPhcZr4M2EEbY4K9cXQgqV6GcVGZzOwFevfx9CZgU2aubj6+ht1BuyUiZmXm5oiYBWxt9Tl2tJLqZYRWHWTmI8BDEXFcc9c84F5gJbCouW8RcH2rkuxoJdXLyK6j/RvgSxFxELABeBe7G9QVEbEY2AgsbHUQg1ZSvYzghb8z807g5L08NW84xzFoJdVLB34zzKCVVCuZ/sKCJJVlRytJhXn1LkkqzI5Wkgrz58YlqTBHB5JUmKMDSSrMoJWkwhwdSFJhngyTpMIcHUhSYY4OJKkwO1pJKsyglaTCMquuYA8GraR66XfVgSSV5ckwSSrMGa0kFeaMVpIKs6OVpMIMWkkqKwf8cUZJKsuOVpIKc3mXJBXWcNWBJJU1gqODiPgpsA0YAPoz8+SImAJ8BTgW+Cnw55n5i6GO0zViFUlSJxgYaH9rzx9n5kmZeXLz8RKgLzPnAH3Nx0Oyoy3oyW3bufDiS3lgw4MQwSfO/yDfXX071668iclHHgHAOX+1iNe88pSKK1UVZs8+iquv+gwzZk6j0WiwdOmX+LfPXll1WWNf+ZNhC4AzmveXAbcA5w31BoO2oIsvvZzTTz2Zf/3kR9m1axe/+vVOvrv6dt751rN419vfUnV5qlh/fz/nfuQi7rjzbg499BDWrL6Jb/bdyrp166subWwbxow2InqAnkG7ejOzd9DjBL4REQl8vvncjMzcDJCZmyNieqvPMWgL2b5jB7ffdTef/OiHAeju7qa7u7viqtRJHnlkK488shWA7dt3cN996zn6qJkG7f4axqqDZnD2DvGS0zPz4WaYroqI+55NSS2DNiKOZ3erfDS70/1hYGVmrns2H3ig2PSzR5h85BF89JOXcP8DGzjhuDks+cBfA7D82v9h5U19nHj8HM59/7s54vDDKq5WVTvmmNmcNPclrF5zR9WljH0juOogMx9u3m6NiOuAU4AtETGr2c3OAra2Os6QJ8Mi4jzgy0AAa4DbmveXR8Q+B8AR0RMRayNi7dJ/X972f1Sd9A8MsO4nD/DWN7+Ba66+jEmTJnLlf6zgrW9+AzeuuIprr76Mac+Zwqc+e0XVpapihxxyMCu+cgUf+rsL2bZte9XljHnZaLS9DSUiDomIw35zHzgTuBtYCSxqvmwRcH2rmlp1tIuBEzNz1zMKuAS4B7h4b28a3I7venRD5y1qGwUzp09lxrSpvPTE4wE484xXsfSLK5g6ZfJvX/OWN72O9517YVUlqgOMHz+e//rKFSxffh1f/eqNVZdTDyP3FdwZwHURAbuz8j8z86aIuA1YERGLgY3AwlYHahW0DeAo4MFn7J/VfE77MPU5U5g5fRr/9+Amnn/MbH5w+5288Njn8fNHH2fa1CkA9P3v93jRC46puFJV6Yref2HdfQ9w6WeGGhNqWEZodJCZG4C5e9n/GDBvOMdqFbQfAPoiYj3wUHPf84AXAe8fzgcdiM7/4Hs476J/Zlf/Lp571Cw+cf4H+adLL+f+9Rsg4OiZM7jwI39bdZmqyOmvfDnvfMdb+NGP72Xtbd8A4IILLubGm26uuLIxrgOvdRDZ4iK5EdHF7gHw0eyez24CbsvMtvrzA3V0oKFNOurVVZegDtT/9M9if4+x4x/ObjtzDvn4l/f789rRctVBZjaAH4xCLZK0/7yojCQV5kVlJKms7PfC35JUlh2tJBXmjFaSCrOjlaSy0qCVpMI8GSZJhdnRSlJhBq0kldXqsgJVMGgl1YsdrSQVZtBKUlnZ7xcWJKmszstZg1ZSvfiFBUkqzaCVpMIcHUhSWY4OJKmw7DdoJaksRweSVFYHXvfboJVUMx0YtF1VFyBJIykb7W/tiIhxEXFHRNzQfDwlIlZFxPrm7eRWxzBoJdVK9re/tekcYN2gx0uAvsycA/Q1Hw/JoJVUKyPZ0UbEbOANwNJBuxcAy5r3lwFntTqOM1pJtTLCJ8MuBT4CHDZo34zM3AyQmZsjYnqrg9jRSqqXjLa3iOiJiLWDtp7fHCYi3ghszczb97ckO1pJtTKcjjYze4HefTx9OvCmiHg9MBE4PCK+CGyJiFnNbnYWsLXV59jRSqqVbETb25DHyfz7zJydmccCZwM3Z+Y7gJXAoubLFgHXt6rJjlZSrTQGhg7QEXAxsCIiFgMbgYWt3mDQSqqVEt8My8xbgFua9x8D5g3n/QatpFppNRKogkErqVY68NfGDVpJ9WJHK0mFjcLJsGEzaCXVih2tJBWWadBKUlFe+FuSCmvY0UpSWY4OJKkwVx1IUmGuOpCkwpzRSlJhzmglqTCvdSBJhTk6kKTCGp4Mk6SyDsiO9rDZZ5T+CI1Bj/3Fi6suQTXlyTBJKuyA7GglaTR14KIDg1ZSvQw0uqouYQ8GraRa6cCrJBq0kuolcUYrSUU1OnBIa9BKqpWGHa0kldWJo4POOz0nSfthgGh7G0pETIyINRFxV0TcExEXNfdPiYhVEbG+eTu5VU0GraRaaQxja2En8NrMnAucBMyPiNOAJUBfZs4B+pqPh2TQSqqVkQra3G1782F3c0tgAbCsuX8ZcFarmgxaSbWSRNtbRPRExNpBW8/gY0XEuIi4E9gKrMrM1cCMzNwM0Lyd3qomT4ZJqpXhXCUxM3uB3iGeHwBOiogjgesi4iXPpiY7Wkm10iDa3tqVmb8EbgHmA1siYhZA83Zrq/cbtJJqZWAY21AiYlqzkyUiJgF/AtwHrAQWNV+2CLi+VU2ODiTVSiNGbB3tLGBZRIxjd1O6IjNviIjvAysiYjGwEVjY6kAGraRaGalv4Gbmj4CX7WX/Y8C84RzLoJVUK169S5IK68DfZjRoJdVLq6/WVsGglVQrdrSSVJgzWkkqrAOv+23QSqoXRweSVJijA0kqbMCOVpLKsqOVpMIMWkkqzFUHklSYqw4kqTBHB5JUWKsLelfBoJVUK44OJKkwRweSVJirDiSpsEYHRq1BK6lWPBkmSYU5o5Wkwlx1IEmFOaOVpMI6L2YNWkk144xWkgob6MCetqvqAiRpJDWGsQ0lIp4bEd+KiHURcU9EnNPcPyUiVkXE+ubt5FY1GbSSaqVBtr210A98ODNfDJwGvC8iTgCWAH2ZOQfoaz4ekkErqVZyGNuQx8ncnJk/bN7fBqwDjgYWAMuaL1sGnNWqJoNWUq0MZ3QQET0RsXbQ1rO3Y0bEscDLgNXAjMzcDLvDGJjeqiZPhkmqleGcDMvMXqB3qNdExKHAtcAHMvPJiOF/I8KglVQrI/mFhYjoZnfIfikz/7u5e0tEzMrMzRExC9ja6jiODkbBhAkT+Pa3V7JmzU388Iff5IILPlR1SapSdHHoxy7n4HP+8fd2HzR/IUd84ZvEoYdXVFg9jNSMNna3rlcC6zLzkkFPrQQWNe8vAq5vVZMd7SjYuXMn8+efzY4dTzF+/Hhuvvlavv71b7FmzR1Vl6YKHPSnb2Zg80Zi4sG/3RdTpjH+xD+i8eiWCiurhxHsaE8H3gn8OCLubO47H7gYWBERi4GNwMJWB7KjHSU7djwFQHf3eLq7x5PZeYuqVV5Mnkr33FN5+tav/d7+SWe/h1+v6KUzv0A6tozUOtrM/E5mRma+NDNPam5fy8zHMnNeZs5p3j7eqiaDdpR0dXWxevWNPPTQHfT1fYfbbruz6pJUgUlvey+/WnEFNH4XqONPegWNXz5K46ENFVZWHzmMP6PlWQdtRLxriOd+u2RiYGD7s/2IWmk0Gpx66ut44QtP5eUvn8sJJ/xB1SVplI2feyqNbb+k8eD63+08aAIT3vh2fn3dsn2/UcMyQLa9jZb9mdFeBHxhb08MXjIxceLz/H+hQZ544kluvfUHnHnmGdx770+qLkejaNycl9B90ivofukp0H0QMfFgDn73ErqmzeSwj38egJg8jUM/djnbP/4+8slfVFzx2DTmLioTET/a11PAjJEvp56mTp3Crl39PPHEk0ycOIHXvvZVfPrTn6u6LI2ynddcyc5rrgRg3HFzmTB/IU9ddtHvveawT32R7Re9l9z+ZBUl1kKjA89/tOpoZwB/Bjzzn9YAvlekohqaOXM6S5dewrhx4+jq6uLaa2/gxhv7qi5LqqXOi9nWQXsDcGhm3vnMJyLilhIF1dHdd9/Haae9vuoy1EEG7r+Lp+6/a4/92859RwXV1MuY+4WFzFw8xHNvH/lyJGn/jOZqgnb5hQVJtdJv0EpSWXa0klTYmFveJUljTSd+vd2glVQrY27VgSSNNZ34K7gGraRasaOVpMKc0UpSYa46kKTCXEcrSYU5o5Wkwgay84YHBq2kWnF0IEmFjcULf0vSmNJ5MWvQSqoZT4ZJUmEGrSQV1omrDrqqLkCSRlIO408rEXFVRGyNiLsH7ZsSEasiYn3zdnKr4xi0kmolM9ve2nA1MP8Z+5YAfZk5B+hrPh6SQSupVhpk21srmXkr8Pgzdi8AljXvLwPOanUcg1ZSrQyno42InohYO2jraeMjZmTm5uZnbQamt3qDJ8Mk1crAMK7flZm9QG+5anYzaCXVyih8M2xLRMzKzM0RMQvY2uoNjg4k1cpIrjrYh5XAoub9RcD1rd5gRyupVkayo42I5cAZwNSI2ARcCFwMrIiIxcBGYGGr4xi0kmplJK/elZlv28dT84ZzHINWUq149S5JKqwTv4Jr0EqqFS/8LUmFpR2tJJXlZRIlqbA2LxYzqgxaSbViRytJhQ00nNFKUlGuOpCkwpzRSlJhzmglqTA7WkkqzJNhklSYowNJKszRgSQV5mUSJakw19FKUmF2tJJUWMPLJEpSWZ4Mk6TCDFpJKqzzYhaiE9O/riKiJzN7q65DncW/F/XXVXUBB5ieqgtQR/LvRc0ZtJJUmEErSYUZtKPLOZz2xr8XNefJMEkqzI5WkgozaCWpMIN2lETE/Ii4PyIeiIglVdej6kXEVRGxNSLurroWlWXQjoKIGAdcBrwOOAF4W0ScUG1V6gBXA/OrLkLlGbSj4xTggczckJlPA18GFlRckyqWmbcCj1ddh8ozaEfH0cBDgx5vau6TdAAwaEdH7GWf6+qkA4RBOzo2Ac8d9Hg28HBFtUgaZQbt6LgNmBMRz4+Ig4CzgZUV1yRplBi0oyAz+4H3A18H1gErMvOeaqtS1SJiOfB94LiI2BQRi6uuSWX4FVxJKsyOVpIKM2glqTCDVpIKM2glqTCDVpIKM2glqTCDVpIK+38NCWslSIYBugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe41bf0",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b6f9171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96        67\n",
      "           1       0.96      0.94      0.95        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcedb74",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bee3bf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this model is 95.6140350877193%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for this model is {}%\".format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39493e05",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb29dae5",
   "metadata": {},
   "source": [
    "- **Breast Cancer Wisconsin (Diagnostic) Data Set**: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "- **Intro to Keras with breast cancer data[ANN]** : https://www.kaggle.com/thebrownviking20/intro-to-keras-with-breast-cancer-data-ann/notebook\n",
    "- **[ANN] Making Model for Binary Classification** : https://www.kaggle.com/mirichoi0218/ann-making-model-for-binary-classification\n",
    "- **Why do we use ReLU in neural networks and how do we use it?** : https://stats.stackexchange.com/questions/226923/why-do-we-use-relu-in-neural-networks-and-how-do-we-use-it\n",
    "- **Activation Functions: Sigmoid, Tanh, ReLU, Leaky ReLU, Softmax** : https://medium.com/@cmukesh8688/activation-functions-sigmoid-tanh-relu-leaky-relu-softmax-50d3778dcea5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
