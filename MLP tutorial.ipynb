{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c01de74",
   "metadata": {},
   "source": [
    "# Intro to Keras with breast cancer data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eaa152",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114a19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d13edce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9   ...     22     23      24      25      26      27      28      29  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"Data/WDBC.csv\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b7ebf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc820cb",
   "metadata": {},
   "source": [
    "## Set features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "685b0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 2:].values\n",
    "y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6990e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8daa6",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae965a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e4d98",
   "metadata": {},
   "source": [
    "## Splitting the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1825a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394fecac",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5bd99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0795d03e",
   "metadata": {},
   "source": [
    "## Define ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d60223ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units=16, kernel_initializer=\"uniform\", activation='relu', input_dim=30))\n",
    "\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe2defe",
   "metadata": {},
   "source": [
    "## Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df07017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477afba5",
   "metadata": {},
   "source": [
    "## Fitting the ANN to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b86300eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.7121\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.8901\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.9165\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.9143\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.9253\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.9297\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.9319\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.9363\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.9363\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.9451\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.9429\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.9451\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.9495\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.9516\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.9451\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.9516\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.9538\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2946 - accuracy: 0.9538\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.9560\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.9582\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.9604\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9648\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9648\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9670\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9670\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9714\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.9670\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9692\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9692\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.9736\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9758\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9736\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.9758\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1449 - accuracy: 0.9736\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.9736\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9736\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9736\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9736\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9736\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9736\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9736\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1156 - accuracy: 0.9736\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9736\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9802\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.9780\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9780\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9758\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9780\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0998 - accuracy: 0.9802\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1000 - accuracy: 0.9802\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0971 - accuracy: 0.9780\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9802\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0963 - accuracy: 0.9780\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9802\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0935 - accuracy: 0.9802\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9824\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9802\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9802\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9802\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9802\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.9802\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9802\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.9802\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0831 - accuracy: 0.9802\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9824\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.9824\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9824\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9824\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9824\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9846\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9824\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9824\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9824\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 0.9824\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0758 - accuracy: 0.9824\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9824\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9824\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9846\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9824\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9846\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9824\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9868\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9846\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9846\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9868\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9868\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9890\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9868\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9868\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9868\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0659 - accuracy: 0.9846\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9846\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9846\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9868\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.9868\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9868\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9868\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9868\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9868\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9868\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9890\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9890\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9890\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9868\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9868\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9846\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9890\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9868\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9868\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9890\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9890\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9890\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9890\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9890\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9890\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9890\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9868\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9868\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9890\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9890\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9890\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9890\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9890\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9890\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9868\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9890\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9890\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9868\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9890\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9890\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9890\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9868\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9890\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9868\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9868\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9890\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9890\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9890\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9890\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9890\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9868\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9890\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9890\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9890\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9890\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9890\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9890\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9890\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9890\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2652d0e1370>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size=100, epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97264ff6",
   "metadata": {},
   "source": [
    "## Predicting the test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e789dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ad62a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37d653",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b92e71e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64,  3],\n",
       "       [ 2, 45]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "293029f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe41bf0",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83308170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96        67\n",
      "           1       0.94      0.96      0.95        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.96      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df8419d",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bab888f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this model is 95.6140350877193%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for this model is {}%\".format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d77ed",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7a2795",
   "metadata": {},
   "source": [
    "- **Breast Cancer Wisconsin (Diagnostic) Data Set**: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "- **Intro to Keras with breast cancer data[ANN]** : https://www.kaggle.com/thebrownviking20/intro-to-keras-with-breast-cancer-data-ann/notebook\n",
    "- **[ANN] Making Model for Binary Classification** : https://www.kaggle.com/mirichoi0218/ann-making-model-for-binary-classification\n",
    "- **Why do we use ReLU in neural networks and how do we use it?** : https://stats.stackexchange.com/questions/226923/why-do-we-use-relu-in-neural-networks-and-how-do-we-use-it\n",
    "- **Activation Functions: Sigmoid, Tanh, ReLU, Leaky ReLU, Softmax** : https://medium.com/@cmukesh8688/activation-functions-sigmoid-tanh-relu-leaky-relu-softmax-50d3778dcea5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
